global NO_REPLICATIONS ITERMAX NA NS SMALL TPM TRM LAMBDA


NO_REPLICATIONS=30; % No of replications of simulation 
ITERMAX=10000; % No of iterations of learning 
NA=5; % Number of actions in each state
NS=5; % Number of states

%NA and NS are equal to 5 because the traffic lights have 5 possible states and actions

LAMBDA=0.8; % discount factor

SMALL=-1000000;

%Let p(i,a, j) (TPM) denote the probability associated with the same transition.
%Let r(i,a, j) (TRM) denote the reward earned in going from state i to state j under action a. 

TPM(:,:,1)=[1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;1,1,1,1,1];

TPM(:,:,2)=[1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;1,1,1,1,1];

TPM(:,:,3)=[1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;1,1,1,1,1];

TPM(:,:,4)=[1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;1,1,1,1,1];

TPM(:,:,5)=[1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;1,1,1,1,1];


TRM(:,:,1)=[1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;1,1,1,1,1];

TRM(:,:,2)=[1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;1,1,1,1,1];

TRM(:,:,3)=[1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;1,1,1,1,1];

TRM(:,:,4)=[1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;1,1,1,1,1];

TRM(:,:,5)=[1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;1,1,1,1,1;1,1,1,1,1];
